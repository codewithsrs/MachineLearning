{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314eda3a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-26T19:08:52.629065Z",
     "iopub.status.busy": "2024-01-26T19:08:52.628388Z",
     "iopub.status.idle": "2024-01-26T19:09:06.763523Z",
     "shell.execute_reply": "2024-01-26T19:09:06.762409Z"
    },
    "papermill": {
     "duration": 14.143355,
     "end_time": "2024-01-26T19:09:06.766080",
     "exception": false,
     "start_time": "2024-01-26T19:08:52.622725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c66374b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.776952Z",
     "iopub.status.busy": "2024-01-26T19:09:06.776378Z",
     "iopub.status.idle": "2024-01-26T19:09:06.780980Z",
     "shell.execute_reply": "2024-01-26T19:09:06.780142Z"
    },
    "papermill": {
     "duration": 0.011835,
     "end_time": "2024-01-26T19:09:06.782900",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.771065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_h = 64\n",
    "img_w = 64\n",
    "img_c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1abb832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.792724Z",
     "iopub.status.busy": "2024-01-26T19:09:06.792461Z",
     "iopub.status.idle": "2024-01-26T19:09:06.796699Z",
     "shell.execute_reply": "2024-01-26T19:09:06.795861Z"
    },
    "papermill": {
     "duration": 0.011476,
     "end_time": "2024-01-26T19:09:06.798732",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.787256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0f704c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.808370Z",
     "iopub.status.busy": "2024-01-26T19:09:06.808119Z",
     "iopub.status.idle": "2024-01-26T19:09:06.812845Z",
     "shell.execute_reply": "2024-01-26T19:09:06.812035Z"
    },
    "papermill": {
     "duration": 0.011607,
     "end_time": "2024-01-26T19:09:06.814766",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.803159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(image_Path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_png(img)\n",
    "    img = tf.cast(img,tf.float32)\n",
    "    img = (img-127.5)/127.5\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd3a54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.824289Z",
     "iopub.status.busy": "2024-01-26T19:09:06.824036Z",
     "iopub.status.idle": "2024-01-26T19:09:06.827553Z",
     "shell.execute_reply": "2024-01-26T19:09:06.826770Z"
    },
    "papermill": {
     "duration": 0.010462,
     "end_time": "2024-01-26T19:09:06.829455",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.818993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for top,dirs, files in os.walk(\"/kaggle/input/animefacedataset/images\"):\n",
    "#     for file in files:\n",
    "#         load_image(os.path.join(top,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01d842e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.839078Z",
     "iopub.status.busy": "2024-01-26T19:09:06.838758Z",
     "iopub.status.idle": "2024-01-26T19:09:06.843891Z",
     "shell.execute_reply": "2024-01-26T19:09:06.843066Z"
    },
    "papermill": {
     "duration": 0.011925,
     "end_time": "2024-01-26T19:09:06.845699",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.833774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tf_dataset(images_path, batch_size):\n",
    "    ds = tf.data.Dataset.from_tensor_silces(images_path)\n",
    "    ds = ds.shuffle(buffer_size = 1000).map(load_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c87897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.856203Z",
     "iopub.status.busy": "2024-01-26T19:09:06.855365Z",
     "iopub.status.idle": "2024-01-26T19:09:06.862333Z",
     "shell.execute_reply": "2024-01-26T19:09:06.861520Z"
    },
    "papermill": {
     "duration": 0.014165,
     "end_time": "2024-01-26T19:09:06.864275",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.850110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    noise = L.Input((latent_dim),name = \"noise_input\")\n",
    "    \n",
    "    x = L.Dense(256)(noise)\n",
    "    x = L.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = L.Dense(1024)(noise)\n",
    "    x = L.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = L.Dense(4096)(noise)\n",
    "    x = L.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = L.Dense(img_h*img_w*img_c)(x)\n",
    "    x = L.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = L.Reshape((img_h,img_w,img_c))(x)\n",
    "    \n",
    "    fake_output = L.Activation(\"tanh\")(x)\n",
    "    \n",
    "    return Model(noise, fake_output, name = \"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5b8df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.874098Z",
     "iopub.status.busy": "2024-01-26T19:09:06.873389Z",
     "iopub.status.idle": "2024-01-26T19:09:06.879931Z",
     "shell.execute_reply": "2024-01-26T19:09:06.879084Z"
    },
    "papermill": {
     "duration": 0.013308,
     "end_time": "2024-01-26T19:09:06.881780",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.868472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    inputs = L.Input((img_h,img_w,img_c), name = \"disc_input\")\n",
    "    \n",
    "    x = L.Flatten()(inputs)\n",
    "    \n",
    "    x = L.Dense(4096)(x)\n",
    "    x = L.LeakyReLU(0.2)(x)\n",
    "    x = L.Dropout(0.3)(x)\n",
    "    \n",
    "    x = L.Dense(1024)(x)\n",
    "    x = L.LeakyReLU(0.2)(x)\n",
    "    x = L.Dropout(0.3)(x)\n",
    "    \n",
    "    x = L.Dense(256)(x)\n",
    "    x = L.LeakyReLU(0.2)(x)\n",
    "    x = L.Dropout(0.3)(x)\n",
    "    \n",
    "    x = L.Dense(1)(x)\n",
    "    \n",
    "    return Model(inputs, x, name = \"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3653499b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.891411Z",
     "iopub.status.busy": "2024-01-26T19:09:06.890938Z",
     "iopub.status.idle": "2024-01-26T19:09:06.900614Z",
     "shell.execute_reply": "2024-01-26T19:09:06.899800Z"
    },
    "papermill": {
     "duration": 0.016413,
     "end_time": "2024-01-26T19:09:06.902441",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.886028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_images, latent_dim, generator, discriminator, g_opt,d_opt):\n",
    "    batch_size= tf.shape(real_images)[0]\n",
    "    bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits = True, label_smoothing = 0.1)\n",
    "    \n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "    for _ in range(2):\n",
    "        with tf.GradientTape() as dtape:\n",
    "            generated_images = generator(noise, training = True)\n",
    "            \n",
    "            real_output = discriminator(real_images, training = True)\n",
    "            fake_output = discriminator(generated_images, training = True)\n",
    "            \n",
    "            d_real_loss = bce_loss(tf.ones_like(real_output), real_output)\n",
    "            d_fake_loss = bce_Loss(tf.zeros_like(fake_output), fake_output)\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            \n",
    "            d_grad = dtape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_opt.apply_gradients(zip(d_grad,discriminator.trainable_variables))\n",
    "            \n",
    "        with tf.GradientType() as gtape:\n",
    "            generated_images = generator(noise, training = True)\n",
    "            fake_output = discriminator(generated_images, training = True)\n",
    "            \n",
    "            g_loss = bce_loss(tf.ones_like(fake_output), fake_output)\n",
    "            \n",
    "            g_grad = gtape.gradient(g_loss,generator.trainable_variables)\n",
    "            g_opt.apply_gradients(zip(g_grad, generator.trainable_variables))\n",
    "            \n",
    "        return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6113eedc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.912092Z",
     "iopub.status.busy": "2024-01-26T19:09:06.911515Z",
     "iopub.status.idle": "2024-01-26T19:09:06.918012Z",
     "shell.execute_reply": "2024-01-26T19:09:06.917201Z"
    },
    "papermill": {
     "duration": 0.013354,
     "end_time": "2024-01-26T19:09:06.919874",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.906520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n):\n",
    "    n = int(n)\n",
    "    examples = (examples+1)/2.0\n",
    "    examples = examples*255\n",
    "    file_name = f\"samples/generated_plot_apoch-{epoch+1}.png\"\n",
    "    \n",
    "    cat_image = None\n",
    "    for i in range(n):\n",
    "        start_idx = i*n\n",
    "        end_idx = (i+1)*n\n",
    "        \n",
    "        image_List = examples[start_idx:end_idx]\n",
    "        if i == 0:\n",
    "            cat_image = np.concatenate(image_list, axis = 1)\n",
    "        else:\n",
    "            tmp = np.concatenate(image_list, axis = 1)\n",
    "            cat_image = np.concatenate([cat_image, tmp], axis = 0)\n",
    "        \n",
    "        cv2.imwrite(file_name,cat_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef91fc1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:06.929630Z",
     "iopub.status.busy": "2024-01-26T19:09:06.929375Z",
     "iopub.status.idle": "2024-01-26T19:09:09.538514Z",
     "shell.execute_reply": "2024-01-26T19:09:09.537539Z"
    },
    "papermill": {
     "duration": 2.637202,
     "end_time": "2024-01-26T19:09:09.561485",
     "exception": false,
     "start_time": "2024-01-26T19:09:06.924283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images :0\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " noise_input (InputLayer)    [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              266240    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12288)             50343936  \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 12288)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50610176 (193.06 MB)\n",
      "Trainable params: 50610176 (193.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " disc_input (InputLayer)     [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12288)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              50335744  \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54793729 (209.02 MB)\n",
      "Trainable params: 54793729 (209.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "latent_dim = 64\n",
    "num_epocs = 1000\n",
    "n_samples = 100\n",
    "\n",
    "images_path = glob(\"/kaggle/input/animefacedataset/images/*.png\")\n",
    "print(f\"images :{len(images_path)}\")\n",
    "\n",
    "create_dir(\"samples\")\n",
    "create_dir(\"saved_model\")\n",
    "\n",
    "g_model = build_generator(latent_dim)\n",
    "d_model = build_discriminator()\n",
    "\n",
    "g_model.summary()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8892cdff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T19:09:09.579967Z",
     "iopub.status.busy": "2024-01-26T19:09:09.579623Z",
     "iopub.status.idle": "2024-01-26T19:09:09.584450Z",
     "shell.execute_reply": "2024-01-26T19:09:09.583704Z"
    },
    "papermill": {
     "duration": 0.016103,
     "end_time": "2024-01-26T19:09:09.586354",
     "exception": false,
     "start_time": "2024-01-26T19:09:09.570251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# d_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_l = 0.5)\n",
    "# g_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_l = 0.5)\n",
    "\n",
    "# images_dataset = tf.dataset(images_path, batch_size)\n",
    "# seed = np.random.normal(size = (n_samples, latent_dim))\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     start = time.time()\n",
    "    \n",
    "#     d_loss = 0.0\n",
    "#     g_loss = 0.0\n",
    "    \n",
    "#     for image_batch in images_dataset:\n",
    "#         d_batch_loss, g_batch_loss = train_step(image_batch, latent_dim, g_model, d_model, g_optimizer, d_optimizer)\n",
    "#         d_loss +=  d_batch_loss\n",
    "#         g_loss += g_batch_loss\n",
    "    \n",
    "#     d_loss = d_loss/len(images_dataset)\n",
    "#     g_loss = g_loss/len(images_dataset)\n",
    "    \n",
    "#     g_model.save(\"saved_model/g_model.h5\")\n",
    "#     d_model.save(\"saved_model/d_model.h5\")\n",
    "    \n",
    "#     examples = g_model.predict(seed, verbose = 0)\n",
    "#     save_plot(examples, epoch, np.sqrt(n_samples))\n",
    "    \n",
    "#     time_taken  = time.time()-start\n",
    "#     print(f\"[{epoch+1:1.0f}/{num_epochs}] {time_taken:2.2f}s - d_loss: {d_loss:1.4f}- g_loss: {g_loss:1.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ab6ea",
   "metadata": {
    "papermill": {
     "duration": 0.008318,
     "end_time": "2024-01-26T19:09:09.603011",
     "exception": false,
     "start_time": "2024-01-26T19:09:09.594693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 379764,
     "sourceId": 737475,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.635694,
   "end_time": "2024-01-26T19:09:12.744338",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-26T19:08:49.108644",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
